---
title: 'DS-UA 201: Final Exam'
author: "Timothy Ng"
date: "December 12, 2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}

library(tidyverse)
library(lsr)
library(haven)
library(estimatr)
knitr::opts_chunk$set(echo = TRUE)
```

# Instructions

> You should submit your writeup (as a knitted .pdf along with the accompanying .rmd file) to the course website before 11:59pm
EST on Saturday December 19th. Please upload your solutions as a .pdf file saved as `Yourlastname_Yourfirstinitial_final.pdf`.
In addition, an electronic copy of your .Rmd file (saved as `Yourlastname_Yourfirstinitial_final.Rmd`) should accompany
this submission.

> Late finals will not be accepted, **so start early and plan to finish early**.
Remember that exams often take longer to finish than you might expect.

>This exam has **3** questions and is worth a total of **50 points**. Show your work in order to receive partial credit.
Also, I will not accept un-compiled .rmd files.

>I general, you will receive points (partial credit is possible) when you demonstrate knowledge about the questions we have asked, you will not receive points when you demonstrate knowledge about questions we have not asked, and you will lose points when you make
inaccurate statements (whether or not they relate to the question asked). Be careful, however, that you
provide an answer to all parts of each question.

> You may use your notes, books, and internet resources to answer the questions below. However, you are
to work on the exam by yourself. You are prohibited from corresponding with any human being
regarding the exam (unless following the procedures below).

> I will answer clarifying questions during the exam. I will not answer statistical
or computational questions until after the exam is over. If you have a question, send email to me. 
If your question is a clarifying one, I will remove all identifying information from the
email and reply on Piazza. Do not attempt to ask us questions in person (or by phone), and do not post
on Piazza.

\pagebreak

# Problem 1 (25 points)

This problem will have you replicate and analyze the results from Moser and Voena's 2012 AER paper on the impact of the World War I "Trading with the Enemy Act" on U.S. domestic invention. The full citation is below

> Moser, P., & Voena, A. (2012). Compulsory licensing: Evidence from the trading with the enemy act. American Economic Review, 102(1), 396-427.

The premise of the study is to evaluate the effect that "compulsory licensing" policy -- that is, policies that permit domestic firms to violate foreign patents and produce foreign inventions without needing to obtain a license from the owner of the foreign patent -- have on domestic invention. Does access to foreign inventions make domestic firms more innovative? The authors leverage an exogenous event in U.S. licensing policy that arose from World War I -- the 1917 "Trading with the Enemy Act" (TWEA) which permitted U.S. firms to violate patents owned by enemy-country firms. This had the consequence of effectively licensing all patents from German-owned firms to U.S. firms after 1918 (that is, from 1919 onward), allowing them to produce these inventions without paying for a license from the German-owned company.

The authors look specifically at domestic innovation and patent activity in the organic chemicals sector. They note that only some of the sub-classes of organic chemicals (as defined by the US Patent Office) received any compulsory licenses under the Trading with the Enemy Act while others did not. They leverage this variation in exposure to the ``treatment" of compulsory licensing to implement a differences-in-differences design looking at domestic firm patent activity in each of these sub-classes (comparing sub-classes that were exposed to compulsory licensing to those that were unexposed).

The dataset is `chem_patents_maindataset.dta` -- the code below will load it.

```{r}
library(tidyverse)
# Read in the Moser and Voena (2012) dataset
chem <- haven::read_dta("chem_patents_maindataset.dta")
```

The unit of the dataset is the sub-class/year (471,120 observations) of 7248 US Patent and Trademark Office (USPTO) patent sub-classes over 65 years.

The relevant variables are

- `uspto_class` - USPTO Patent Sub-Class (unit)
- `grntyr` - Year of observation (year)
- `count_usa` - Count of patents granted to US-owned firms in the year
- `count_france` - Count of patents granted to French-owned firms in the year
- `count_for` - Count of patents granted to foreign-owned (non-US) firms in the year
- `treat` - Treatment indicator -- Whether the patent sub-class received any German patents under TWEA (after 1918 when the policy went into effect) (Note that this is not an indicator for the overall treatment *group* (whether the unit *ever* received treatment) -- it is only 1 after 1918 for units that receive treatment but is still 0 for those ``treated" units prior to the initiation of treatment)

## Question A (5 points)

If you try to use a two-way fixed effects estimator on the dataset as it is, it will likely freeze up your computer as this is a *very large* dataset. We'll instead first aggregate the data in a way that will let you use a simple difference-in-differences estimator to estimate the treatment effect.

Generate a point estimate for the average treatment effect of receiving treatment on the average annual count of US patents using a difference-in-differences estimator (using all post-treatment (1919-1939) and pre-treatment (1875-1918) time periods. You should aggregate your data such that the outcome is the post-/pre- difference in the outcome (preferably using `tidyverse` functions like `group_by` and `summarize`) and each row is a USPTO patent sub-class (rather than a sub-class/year observation) and use a difference-in-means estimator with the differenced outcome. Again, if you use `lm_robust` or even `lm` with two-way fixed effects, your computer will likely freeze up as there are many FE parameters to estimate.

Provide a 95\% robust confidence interval and interpret your point estimate. Do we reject the null of no treatment effect at the $\alpha = .05$ level?


```{r}

#First, we aggregate the data 

chem_aggregate = chem %>% group_by(uspto_class) %>% summarise(us_patents_pre = mean(count_usa[grntyr < 1919]),us_patents_post = mean(count_usa[grntyr > 1918]),treat = (sum(treat))/21,.groups = "keep") #I divide by 21 because the sum of all treated subclasses was 21 and so this value can be used as an indicator for treatment after dividing


#What's the difference in count of US patents?

chem_aggregate$CHNGEUSPATENT = chem_aggregate$us_patents_post - chem_aggregate$us_patents_pre

#DiD estimate 

didreg = lm_robust(CHNGEUSPATENT ~ treat, data=chem_aggregate)

summary(didreg)


```

Our point-estimate of 0.2553 suggests that receiving any German patents under TWEA significantly increased the count of US patents for any particular USPTO patent subclass. Our 95% confidence interval [0.1814   0.3292] indicates a similar evaluation. We also reject the null of no average treatment effect at the $\alpha = .05$ level as our p-value is 1.352e-11

## Question B (5 points)

A colleague suggests that you should instead just compare the average differences in the count of US patents in the post-1918 period between exposed and unexposed sub-classes to estimate the treatment effect. Based on what we observe in the pre-1919 period, is ignorability of the treatment likely to hold under this strategy? Discuss why or why not -- what do you observe in the patent counts in the pre-treatment period between exposed and unexposed subclasses.

Ignorability of the treatment is unlikely to hold under this strategy. If we look to the the pre-1919 period we will see that there is a stark contrast in patent counts between those who were exposed and those who were unexposed to treatment. The contrast being that nearly all of those subclasses who were exposed to treatment had 0 patent counts during the pre-treatment period. This suggests that treatment was most likely not independent of the outcomes and so ignorabiltiy would not hold. 


## Question C (5 points)

The authors implement a test of their identification assumptions by also estimating the effect (using the differences-in-differences design) of the Trading with the Enemy Act on patents granted by French firms, which the authors note "could not license enemy patents under the TWEA." Describe what sort of a diagnostic strategy this is. What do the authors expect to find if their parallel trends assumption holds?

Estimate the effect of TWEA exposure on the count of French firm patents using a difference-in-differences design and provide a a 95\% robust confidence interval. Are the results consistent with what the authors expect if their design assumptions hold?


The diagnostic strategy at work here is a placebo test. The authors know that, given the parallel trends assumption holds, since the patents granted by French firms should not have been affected by the TWEA, the effect of the TWEA on patents granted by French firms should be 0 or at least close to 0. 

```{r}

chem_aggregate_fr = chem %>% group_by(uspto_class) %>% summarise(fr_patents_pre = mean(count_france[grntyr < 1919]),fr_patents_post = mean(count_france[grntyr > 1918]),treat = (sum(treat))/21,.groups = "keep")

#What's the difference in count of French patents?

chem_aggregate_fr$CHNGEFRPATENT = chem_aggregate_fr$fr_patents_post - chem_aggregate_fr$fr_patents_pre

#DiD estimate 

didreg = lm_robust(CHNGEFRPATENT ~ treat, data=chem_aggregate_fr)

summary(didreg)


```

Our results suggest that the authors are right to think that the parallel trends assumption holds since we find there to be a very minimal effect (-0.00203). Also, our confidence interval is [-0.0095803 0.005521] which supports the claim that there isn't really an effect and we reject the null of no average treatment effect at the $\alpha = .05$ level too (p-value of 0.5982).

## Question D (5 points)

We might be concerned that there are differential trends in pre-treatment patenting between those sub-classes exposed to the treatment and those exposed to control. Estimate the difference in the trend in US patents between exposed and unexposed sub-classes from 1918 to 1917, 1916, 1915, and 1914 (four estimates in total: 1918-1917, 1918-1916, 1918-1915, 1918-1914). Provide a 95\% robust confidence interval for each of these estimates and interpret your results. Do we reject the null that any of these differ from $0$ (at $\alpha = .05$)? If the outcome trends were evolving in parallel between the, what would we expect these estimates to be? What do your results suggest for the validity of the parallel trends assumption?


```{r}

#difference 1918,1917

#First, we aggregate the data 

chem_1918_1917 = chem %>% group_by(uspto_class) %>% summarise(us_patents_1918 = mean(count_usa[grntyr == 1918]),us_patents_1917 = mean(count_usa[grntyr == 1917]),treat = (sum(treat))/21,.groups = "keep")

#What's the difference in count of US patents?

chem_1918_1917$CHNGEUSPATENT = chem_1918_1917$us_patents_1918 - chem_1918_1917$us_patents_1917


#change in trends between exposed and unexposed
didreg = lm_robust(CHNGEUSPATENT ~ treat, data = chem_1918_1917)

summary(didreg)


```

Our results suggest a very small difference in trend but nothing too significant. We also reject the null of no average treatment effect at the $\alpha = .05$. Our confidence interval [ -0.06049  0.114558] contains 0 and so supports this evaluation.

```{r}

#difference 1918,1916

#First, we aggregate the data 

chem_1918_1916 = chem %>% group_by(uspto_class) %>% summarise(us_patents_1918 = mean(count_usa[grntyr == 1918]),us_patents_1916 = mean(count_usa[grntyr == 1916]),treat = (sum(treat))/21,.groups = "keep")

#What's the difference in count of US patents?

chem_1918_1916$CHNGEUSPATENT = chem_1918_1916$us_patents_1918 - chem_1918_1916$us_patents_1916


#change in trends between exposed and unexposed
didreg = lm_robust(CHNGEUSPATENT ~ treat, data = chem_1918_1916)

summary(didreg)


```
Our results suggest a very small difference in trend but nothing too significant. We do, however, reject the null of no average treatment effect at the $\alpha = .05$ level. Our confidence interval [ 0.02432  0.16843] supports this evaluation.


```{r}
#difference 1918,1915

#First, we aggregate the data 

chem_1918_1915 = chem %>% group_by(uspto_class) %>% summarise(us_patents_1918 = mean(count_usa[grntyr == 1918]),us_patents_1915 = mean(count_usa[grntyr == 1915]),treat = (sum(treat))/21,.groups = "keep")

#What's the difference in count of US patents?

chem_1918_1915$CHNGEUSPATENT = chem_1918_1915$us_patents_1918 - chem_1918_1915$us_patents_1915


#change in trends between exposed and unexposed
didreg = lm_robust(CHNGEUSPATENT ~ treat, data = chem_1918_1915)

summary(didreg)



```
Our results suggest a very small difference in trend. Also, we fail to reject the null of no average treatment effect at the $\alpha = .05$ level as we have a p value of 0.9315. Our confidence interval [-0.003801  0.13095] which contains 0 supports this evaluation that our results are insignificant.

```{r}

#difference 1918,1914

#First, we aggregate the data 

chem_1918_1914 = chem %>% group_by(uspto_class) %>% summarise(us_patents_1918 = mean(count_usa[grntyr == 1918]),us_patents_1914 = mean(count_usa[grntyr == 1914]),treat = (sum(treat))/21,.groups = "keep")

#What's the difference in count of US patents?

chem_1918_1914$CHNGEUSPATENT = chem_1918_1914$us_patents_1918 - chem_1918_1914$us_patents_1914


#change in trends between exposed and unexposed
didreg = lm_robust(CHNGEUSPATENT ~ treat, data = chem_1918_1914)

summary(didreg)


```
Our results suggest a very small difference in trend but nothing too significant though this time it is negative. We also reject the null of no average treatment effect at the $\alpha = .05$ level. Our confidence interval [-0.10109  0.05368] contains 0 and so supports this evaluation.


If the parallel trends assumption were true in this case, we would expect the difference in trends for each of our estimates to be either significantly positive or significantly negative. The fact that this is not the case in most of our estimates, supports the conclusion that our parallel trends assumption holds. The only exception is that our results from a comparison between 1918 and 1916 seem to show some evidence of a difference in the trends between exposed and unexposed subclasses. However, since the effect is not that large I think it is safe to assume that there wasn't a huge difference in trends between the exposed and unexposed groups.  


## Question E (5 points)

The authors adjust for covariates out of concern for possible parallel trends violations. One possible confounder that might be driving a parallel trends violation is the overall amount of foreign patenting in the sub-class and its change over time -- reflecting general technological differences that might differ between the patent sub-classes. Since the treatment does not affect the amount of foreign patenting, this is a valid control. 

Create a variable for the change between the post- and pre-treatment count of foreign patents in the USPTO subclass. Bin this variable into six (6) roughly-equally sized strata and estimate the effect of the treatment on US patenting (again using the differenced outcome) using a stratified difference-in-means estimator. Provide a robust 95\% confidence interval and interpret your results. Do we reject the null of no treatment effect at the $\alpha = .05$ level? Compare your results to your estimate from Question A and discuss why they might differ.

```{r}

#First, we aggregate the data 

chem_aggregate_for = chem %>% group_by(uspto_class) %>% summarise(for_patents_pre = mean(count_for[grntyr < 1919]),for_patents_post = mean(count_for[grntyr > 1918]),treat = (sum(treat))/21,us_patents_pre = mean(count_usa[grntyr < 1919]),us_patents_post = mean(count_usa[grntyr > 1918]),.groups = "keep")


#What's the difference in count of foreign patents?

chem_aggregate_for$CHNGEFORPATENT = chem_aggregate_for$for_patents_post - chem_aggregate_for$for_patents_pre

#What's the difference in count of US patents?

chem_aggregate_for$CHNGEUSPATENT = chem_aggregate_for$us_patents_post - chem_aggregate_for$us_patents_pre


#bin variable into 6 strata 
chem_aggregate_for$stratum <- quantileCut(chem_aggregate_for$CHNGEFORPATENT, 6)


## Validate the split is roughly even
table(chem_aggregate_for$stratum)


```

```{r}

diff_in_means <- function(treated, control){
  # Point Estimate
  point <- mean(treated) - mean(control)
  
  # Standard Error
  se <- sqrt(var(treated)/length(treated) + var(control)/length(control))
  
  # Asymptotic 95% CI
  ci_95 <- c(point - qnorm(.975)*se,
             point + qnorm(.975)*se)
  
  # P-value 
  pval <- 2*pnorm(-abs(point/se))

  # Return as a data frame
  output <- data.frame(meanTreated = mean(treated), meanControl = mean(control), est = point, se = se, ci95Lower = ci_95[1], ci95Upper = ci_95[2], pvalue = pval, N= length(treated) + length(control))
  
  return(as_tibble(output))

}

```

```{r}

# Outcome: Vector of all outcomes
# Treatment: Vector of treatment indicators
# Stratum: Character vector indicating unique stratum
strat_diff_in_means <- function(outcome, treatment, stratum){
  
  # For each stratum
  strat_ests <- bind_rows(map(unique(stratum), function(x) diff_in_means(outcome[treatment == 1&stratum == x], outcome[treatment==0&stratum == x])))
  
  # Normalize weights to sum to 1
  strat_ests$weight <- strat_ests$N/sum(strat_ests$N)
  
  # Point estimate
  point = sum(strat_ests$est*strat_ests$weight)
  
  # Standard error
  se = sqrt(sum(strat_ests$se^2*strat_ests$weight^2))
  

  # Asymptotic 95% CI
  ci_95 <- c(point - qnorm(.975)*se,
             point + qnorm(.975)*se)
  
  # P-value 
  pval <- 2*pnorm(-abs(point/se))

  # Return as a data frame
  output <- data.frame(est = point, se = se, ci95Lower = ci_95[1], ci95Upper = ci_95[2], pvalue = pval, N= length(outcome))
  
  return(as_tibble(output))
  
}

```

```{r}
strat_diff_in_means(chem_aggregate_for$CHNGEUSPATENT, chem_aggregate_for$treat, chem_aggregate_for$stratum)

```

From our results, we see that the size of our point estimate has undergone a significant decrease (0.255 vs 0.095). Our confidence interval [0.01964558	0.1700252] supports this evaluation. However, we should note that through our p-value being above the level of $\alpha = .05$ (our p-value is 0.0134) we reject the null of no average treatment effect, indicating that the treatment still increased the count of US patents. The reason for this decrease in our estimate might be because there was, in actual fact, some confounding in our results due to some patent sub-classes receiving more foreign patenting than other sub-classes. As a result, when we adjust for this fact, we find the effect to be smaller than previously thought. 



# Problem 2 (5 points)

This problem will ask you to demonstrate that the propensity score is a ``balancing score" -- that is that, conditional on the propensity score, the potential outcomes are independent of the treatment (and we don't need to condition on anything else besides the propensity score). Assume our usual set-up for a design with selection-on-observables. Let $Y_i(1)$ and $Y_i(0)$ denote the potential outcomes under treatment and control respectively. $Y_i$ is our observed outcome and $D_i$ is our observed treatment. We assume *conditional ignorability* -- that conditional on pre-treatment covariates $X_i$, treatment $D_i$ is independent of the potential outcomes.

$$
Y_i(1), Y_i(0) \perp D_i | X_i
$$
We also assume positivity 

$$
0 < Pr(D_i = 1 | X_i) < 1 
$$
and consistency (as usual).

$$
Y_i(d) = Y_i \text{ if } D_i = d
$$
Define the propensity score $e(X_i)$ as the probability of treatment given covariates $X_i$

$$
e(X_i) = Pr(D_i = 1 | X_i)
$$
Show that it is also true that 

$$
Y_i(1), Y_i(0) \perp D_i | e(X_i)
$$
In other words, that ignorability holds conditional on the propensity score alone.

- Hint 1: It suffices to show that the probability of treatment given the propensity score does not change when we further condition on the potential outcomes $Y_i(1)$ and $Y_i(0)$.
- Hint 2: Condition on $X_i$ and use the law of total expectations.
- Hint 3: Remember the ``fundamental bridge" -- for any binary (0/1) random variable $A$, $E[A] = Pr(A = 1)$ 



Let $Y_i(1), Y_i(0) \perp D_i | e(X_i)$ be written as $Y_{ji}\perp D_i | X_i$ where j is either 1 or 0.

If we want to show that the potential outcomes are independent of treatment conditional solely on the propensity score, then it suffices to show that $Pr(D_i = 1 | Y_{ji}|e(X_i)) \ne f(Y_{ji})$ 


$$
Pr(D_i = 1 | Y_{ji}|e(X_i)) \ne f(Y_{ji})
$$

We also know that $Pr(D_i = 1 | Y_{ji}|e(X_i))$ is equal to $E[D_i| Y_{ji}|e(X_i)]$ since


$$
E[D_i| Y_{ji}|e(X_i)] = 1* Pr(D_i = 1 | Y_{ji}|e(X_i)) + 0*Pr(D_i = 0 | Y_{ji}|e(X_i))\\
= Pr(D_i = 1 | Y_{ji}|e(X_i))
$$

Then, using the law of total expectation and conditioning on the set of covariates $X_i$

$$
E[D_i| Y_{ji}|e(X_i)]\\
= E[E[D_i| Y_{ji}|e(X_i)|X_i]|Y_{ji}|e(X_i)\\
$$
Now, given our assumptions of conditional ignorability, we know that $Y_i(1), Y_i(0) \perp D_i | X_i$ or as I've written it here, $Y_{ji}\perp D_i | X_i$. Also, we know if we have $X_i$ we have $e(X_i)$ so we can remove this conditioning from the inner expectation as follows:

$$
E[E[D_i| Y_{ji}|e(X_i)|X_i]|Y_{ji}|e(X_i)\\
= E[E[D_i|X_i]|Y_{ji}|e(X_i)
$$

But since the $E[D_i|X_i]$ is just the propensity score, we can substitute this with $e(X_i)$. Furthermore, given that we are already conditioning on the propensity score, the expected value of the propensity score will simply be the propensity score. 

$$
E[E[D_i|X_i]|Y_{ji}|e(X_i)\\
=E[e(X_i)|Y_{ji}|e(X_i)\\
= e(X_i)\\
e(X_i) \ne f(Y{ji})\\
\therefore Y_{ji} \perp D_i | e(X_i)
$$

This importantly is not a function of $Y_{ji}$ and so if it is the case that the conditional ignorability assumption holds, we can know that $Y_{ji} \perp D_i | e(X_i)$ which is what we set out to prove. 

q
# Problem 3 (20 points)

This problem examines a study by Acemoglu, Johnson and Robinson examining the effect of political institutions on economic development.

> Acemoglu, D., Johnson, S., & Robinson, J. A. (2001). The colonial origins of comparative development: An empirical investigation. American economic review, 91(5), 1369-1401.

The authors are interested in whether robust political institutions with protections on private property encourage economic growth and raise GDP per capita. However, institutions are not randomly assigned.

The authors leverage historical variation in the types of political institutions established by Europeans during the colonial period in different parts of the world. The authors posit that in regions where early settler mortality rates were low, settlers were more likely to establish robust political institutions with limitations on government power. Conversely, in areas where early settler mortality was high, settlers instead established "extractive" institutions with weak checks on government power, designed primarily to transfer resource wealth to the colonizers. The authors argue that even after decolonization and independence, the structure of these institutions persisted in the countries, affecting subsequent economic growth and development.

The relevant dataset is `ajr-aer.dta` dataset. The code below loads in the dataset and subsets it down to the relevant observations.

```{r, echo=T, message=F}
library(tidyverse)
library(haven)

# Load in exercise dataset
ajr <- haven::read_dta("ajr-aer.dta")
# Subset down to the original dataset
ajr <- ajr %>% filter(baseco == 1)
```

The variables of interest are:

- `logpgp95` - Logged GDP per capita in 1995 (outcome)
- `avexpr` - average state protection against property expropriation risk (treatment)
- `logem4` - logged historical settler mortality rates (instrument)
- `lat_abst` - Absolute value of the latitude of capital divided by 90

### Question A (5 points)

Note that the instrument here is continuous as is the treatment (quality of political institutions as measured by average expropriation risk). The authors will assume linear models for the relationship between instrument and treatment and treatment and outcome as will we in this problem.

Fit a (robust) linear regression model for the first stage (using `lm_robust`), predicting the average expropriation risk conditional on logged historical settler mortality rates. Provide a point estimate and 95\% confidence interval for the marginal effect of a one unit increase in logged historical settler mortality rates on average expropriation risk. Interpret the estimate and discuss whether we would reject the null of no effect at the $\alpha = .05$ level.

```{r}

#fit linear regression model 

first_stage = lm_robust(avexpr ~ logem4, data = ajr)

summary(first_stage)




```

Our results suggest that an increase in logged historical mortality rate decreases the average state protection against property expropriation risk significantly (point estimate of -0.6). This is a significant effect, however, our F-statistic (15.73) paints this to be only a moderately strong instrument. Our confidence interval [-0.9126  -0.3009 ] indicates the significance of this effect,however, as does our p-value which is below the $\alpha = .05$ level . Also, this is in line with the theory the authors posit, that regions with lower mortality rates tended to have more restrictions on the powers of government and therefore better protection against property expropriation risk. 


### Question B (5 points)

Using the two-stage least squares estimator (assuming linearity), estimate the effect of a one-unit increase in average expropriation risk on logged GDP per capita in 1995 (assuming a linear relationship), instrumenting for average expropriation risk using logged historical settler mortality rates. Provide a point estimate and 95\% confidence interval. Interpret your results and discuss whether we would reject the null of no effect at the $\alpha = .05$ level.


```{r}

twosls = iv_robust(logpgp95 ~ avexpr|logem4, data= ajr)

summary(twosls)



```

Our results suggest that logged GDP per capita in 1995 increased enormously as the average state protection against property expropriation risk increased. This indicates that average state protection against property expropriation risk has an extremely strong positive influence on logged GDP per capita in 1995. Our 95% confidence interval of [ 0.5793    1.309] supports this conclusion as does our p-value of 2.639e-06 which is well below the level of $\alpha = .05$ leading us to reject the null of no effect. 

### Question C (5 points)

Discuss whether the instrumental variables assumptions hold in this case. Evaluate exogeneity of the instrument in particular by examining whether the instrument and outcome are possibly confounded by geography (here, as measured by the absolute value of the latitude (deviation from the equator)). 

When we have an instrumental variables design we take four assumptions to be true: randomization of our instrument, the exclusion restriction, a first stage relationship between our instrument and treatment, and finally monotonicity. In our case here, if we want to be sure of the exogeneity of our treatment, that is that our treatment is randomized, then we will want to know whether there is any confounding going on particularly with respect to geography. We can do this by running a regression with geography (in this case deviation from the equator) controlled for. If there isn't any confounding going on due to this variable, our estimate with this variable controlled for should be the same, or at least very similar, to our estimate without it controlled for. 

```{r exogeneity}

#run a regression with geography controlled for

with = lm_robust(logpgp95 ~ logem4 + lat_abst, data= ajr)

#run a regression without geography controlled for 
without = lm_robust(logpgp95 ~ logem4, data= ajr)


summary(with)

summary(without)

```
As we can see from the two regressions. Our estimates for both are very similar with or without geography accounted for. This suggests that there isn't any confounding at work with respect to geography.

The exclusion restriction is also likely to hold here. After all, how could logged historical mortality rate be affecting logged GDP per capita in 1995 other than by way of our treatment? 

As it pertains to a first-stage relationship between our instrument and treatment, our first stage regression already shows there to be one, albeit the relationship is not as strong as we would like. 

Finally, monotonicity is also likely to hold here as there is little reason to believe, given what the authors have said, that there are any units who would defy encouragement from the instrument, In this case that there would be any countries with a high logged historical mortality rate that continue to have low average protection rates against property expropriation risks. 



### Question D (5 points)

Again, assuming linearity, and using the two-stage least squares estimator estimate the effect of a one-unit increase in average expropriation risk on logged GDP per capita in 1995, instrumenting for average expropriation risk using logged historical settler mortality rates but now assuming that the instrument is valid only conditional on the country's distance from the equator (absolute value of latitude divided by 90). Provide a point estimate and 95\% confidence interval. Interpret your results and discuss whether we would reject the null of no effect at the $\alpha = .05$ level. How do your results differ from your estimates in B?


```{r}

twosls = iv_robust(logpgp95 ~ avexpr + lat_abst|logem4 + lat_abst, data= ajr)

summary(twosls)


```
Our results show that, when we assume the instrument is only valid conditional on our deviation from the equator variable that our estimate increases though not too significantly (0.94 vs 0.99). Our confidence interval is [0.4912 , 1.500] and we reject the null of no effect at $\alpha = .05$. This means that when the logged historical mortality rate is conditioned on deviation from the equator, we see that a marginal increase in state protection against average expropriation risk equates to a bigger increase in logged GDP per capita in 1995 than we had previously seen. 
